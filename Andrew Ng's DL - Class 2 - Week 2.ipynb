{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Mini-batch gradient descent\n",
    "### 2.1.1 Concepts\n",
    "- Variants of gradient descent\n",
    "    - **(Batch) gradient descent**: whole training set at each training step. Batch gradient descent is guaranteed to converge to the global minimum for convex cost function and to a local minimum  for non-convex cost function [1].\n",
    "    - **Mini-batch gradient descent**: `batch_size` samples at each training step. `batch_size` is a **hyper-parameter** (which should be finetuned) and commonly used value is 32, 64, 128, 256, 512.\n",
    "    - **Stochastic gradient descent**: one sample at each training step. With the help of slowly decreased learning rate, stochastic gradient descent has the same convergence trendency as the batch gradient descent [1].\n",
    "\n",
    "- Rule of thumb\n",
    "    - When the size of training set is less than 2000, use batch gradient descent.\n",
    "    - Otherwise, use mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Mini-batch gradient descent implementation\n",
    "- Step1: **Shuffle**.\n",
    "    - Random shuffling is done **synchronously** between X and Y. \n",
    "    - `np.random.permutation()`: return the permuted range.\n",
    "- Step2: **Partition**.\n",
    "    - Partition the shuffled (X, Y) into mini-batches of size `mini_batch_size`. Note that the size of last mini-batch might be smaller than `mini_batch_size`. \n",
    "    - `math.floor()`: round to the nearest integer. `floor(3.9)=3.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y).\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector, of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size)\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Exponentially weighted averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ V_{t} = \\beta V_{t-1} + (1 - \\beta) \\theta_{t}$\n",
    "- $ V_{t} $ can approximately average $ 1 / (1 - \\beta) $ previous $ \\theta$s. The larger $ \\beta $, the more concentrates on pervious $\\theta$s.\n",
    "- **Bias correction**: $ V_{t} = V_{t} / (1 - \\beta^{t})$.\n",
    "- Exponentially weights: more weights on present $\\theta$s and exponentially decayed weights on previous $\\theta$s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Variants of gradient descent optimization algorithm\n",
    "### 2.3.1 Momentum\n",
    "- It uses exponentially weighted average of gradients to update parameter. \n",
    "- If $\\beta = 0$, it is just standard gradient descent without momentum. Common values for $\\beta$ range from 0.8 to 0.999 and $\\beta = 0.9$ is often a reasonable default. \n",
    "- The momentum term **increases updates** for dimensions whose gradients point in the **same directions** and **reduces updates** for dimensions whose gradients **change directions**. As a result, it gains faster convergence and reduced oscillation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The momentum update rule is, for $l = 1, ..., L$: \n",
    "\n",
    "$$ \\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}\n",
    "\\end{cases}$$\n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\\\\n",
    "b^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}} \n",
    "\\end{cases}$$\n",
    "\n",
    "where L is the number of layers, $\\beta$ is the momentum and $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 RMSprop (Root mean square prop)\n",
    "- It uses exponentially weighted average of the squares of the past gradients to update parameters.\n",
    "\n",
    "The update rule is, for $l = 1, ..., L$: \n",
    "\n",
    "$$\\begin{cases}\n",
    "s_{dW^{[l]}} = \\beta_2 s_{dW^{[l]}} + (1 - \\beta_2) (\\frac{\\partial \\mathcal{J} }{\\partial W^{[l]} })^2 \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{1}{\\sqrt{s_{dW^{[l]}}} + \\varepsilon}\n",
    "\\end{cases}$$\n",
    "\n",
    "where:\n",
    "- L is the number of layers\n",
    "- $\\alpha$ is the learning rate\n",
    "- $\\varepsilon$ (default value is 1e-8) is a very small number to avoid dividing by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Adam (Adaptive moment estimation)\n",
    "- It combines an **exponentially weighted average of past gradients with bias correction** and an **exponentially weighted average of the squares of the past gradients with bias correction**. \n",
    "\n",
    "The update rule is, for $l = 1, ..., L$: \n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta_1 v_{dW^{[l]}} + (1 - \\beta_1) \\frac{\\partial \\mathcal{J} }{ \\partial W^{[l]} } \\\\\n",
    "v^{corrected}_{dW^{[l]}} = \\frac{v_{dW^{[l]}}}{1 - (\\beta_1)^t} \\\\\n",
    "s_{dW^{[l]}} = \\beta_2 s_{dW^{[l]}} + (1 - \\beta_2) (\\frac{\\partial \\mathcal{J} }{\\partial W^{[l]} })^2 \\\\\n",
    "s^{corrected}_{dW^{[l]}} = \\frac{s_{dW^{[l]}}}{1 - (\\beta_2)^t} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{v^{corrected}_{dW^{[l]}}}{\\sqrt{s^{corrected}_{dW^{[l]}}} + \\varepsilon}\n",
    "\\end{cases}$$\n",
    "where:\n",
    "- t counts the number of steps taken of Adam \n",
    "- L is the number of layers\n",
    "- $\\beta_1$ (default value is 0.9) and $\\beta_2$ (default value is 0.999) are hyperparameters that control the two exponentially weighted averages. [2]\n",
    "- $\\alpha$ is the learning rate\n",
    "- $\\varepsilon$ (default value is 1e-8) is a very small number to avoid dividing by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Other concepts \n",
    "- **Epoch**: a single pass through the whole training set.\n",
    "- **Saddle points**\n",
    "    - Point where one dimension is a local minimum point and another dimension is a local maximum point.\n",
    "    - They are usually surrounded by a **plateau of zero gradients** in all dimensions.\n",
    "- **Learning rate decay**\n",
    "    - $ \\alpha = \\alpha_0 * 1.0 / (1.0 + decayRate * numEpoch)$\n",
    "    - Exponential decay: $ \\alpha = \\alpha_0 * 0.95^{numEpoch}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:  \n",
    "[1] http://ruder.io/optimizing-gradient-descent/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
