{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Orthogonalization\n",
    "From wikipedia:  \n",
    "In linear algebra, **orthogonalization** is the process of finding a set of orthogonal vectors that span a particular subspace.  \n",
    "\n",
    "For machine learning, orthogonalization ensures that modifying a component of an algorithm will not create side effects to other components of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Single value evaluation metric\n",
    "### Precision\n",
    "precision = True Positive / (True Positive + False Positive)\n",
    "### Recall\n",
    "recall = True Positive / (True positive + False Negative)\n",
    "### F1\n",
    "F1 = 2 / (1/P + 1/R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Optimizing and satisficing metric\n",
    "If we have several evaluation metrics, we can set one metric as optimizing metric (such as accuracy) and others as satisficing metrics (such as running time etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Training, develpoment and testing dataset\n",
    "### 1.4.1 dataset building\n",
    "Development dataset and testing dataset should have the **same distribution** and be taken **randomly** from the whole data.\n",
    "### 1.4.2 dataset size\n",
    "Rule of thumb:  \n",
    "when the size of whole dataset is not large, **60% training + 20% development + 20% testing**.  \n",
    "when you have big data, the proportion does not matter too much, but the size of development and testing dataset **should be large enough** to give better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.5 Bayes optimal error\n",
    "It is defined as the best possible error in theory. And human-level performance can be close to Bayes optimal error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Weighted cost function\n",
    "We can assign different penalization weights to different wrong category. See the following cost function:\n",
    "$$J = \\frac{1}{\\sum\\limits_{i=1}^{m} w_i}\\sum\\limits_{i=1}^{m} w_{i} * I(y^{i'} != y^{i}) $$\n",
    "\n",
    "where $w_{i} = 1$ for not specific category and $w_{i} = 10$ for specific category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
